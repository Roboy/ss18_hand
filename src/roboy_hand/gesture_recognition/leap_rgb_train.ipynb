{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#dataset\n",
    "import torch.utils.data as utils\n",
    "\n",
    "#For paths\n",
    "import glob\n",
    "\n",
    "#imread\n",
    "from skimage import io, transform\n",
    "\n",
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Timestamp\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = \"D:/Downloads/kinect_leap_dataset/acquisitions\"\n",
    "p_id = [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"P10\", \"P11\", \"P12\", \"P13\", \"P14\"]\n",
    "g_id = [\"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\", \"G8\", \"G9\", \"G10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\n",
      "['D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\10_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\1_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\2_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\3_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\4_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\5_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\6_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\7_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\8_rgb.png', 'D:/Downloads/kinect_leap_dataset/acquisitions/P1/G1\\\\9_rgb.png']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(root_path + \"/P1/G1\")\n",
    "files = glob.glob(root_path + \"/P1/G1/\" + \"*rgb.png\")\n",
    "print(files)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "for p in p_id:\n",
    "    for g in g_id:\n",
    "        #print(p, g)\n",
    "        image_names = glob.glob(root_path + \"/\" +  p + \"/\" + g + \"/\" + \"*rgb.png\")\n",
    "        for img_path in image_names:\n",
    "            img = io.imread(img_path)\n",
    "            img = transform.rescale(img, 1.0 / 20.0)\n",
    "\n",
    "            #img = np.resize(img,(3, 48, 64))\n",
    "            img = np.moveaxis(img, [0, 1, 2], [1, 2, 0])\n",
    "            \n",
    "            dataset.append(img)\n",
    "            \n",
    "            #label 10 will be 0\n",
    "            tmp = np.zeros(10)\n",
    "            tmp[int(g[-1])] = 1\n",
    "            labels.append(tmp)\n",
    "            #labels.append(int(g[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ffs\n",
    "dataset = np.array(dataset).astype(float)\n",
    "labels = np.array(labels).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))\n",
    "print(type(dataset))\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(dataset, labels, test_size=0.2)\n",
    "print(type(X_train))\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.from_numpy(dataset).float()\n",
    "labels = torch.from_numpy(labels).float()\n",
    "print(type(dataset))\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "y_val = torch.from_numpy(y_val).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_dataset = utils.TensorDataset(dataset, labels) # create your dataset\n",
    "my_dataloader = utils.DataLoader(my_dataset, batch_size=10, shuffle=True, num_workers=4) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = utils.TensorDataset(X_train, y_train) # create your dataset\n",
    "train_loader = utils.DataLoader(my_dataset, batch_size=10, shuffle=True, num_workers=4) # create your dataloader\n",
    "\n",
    "my_dataset = utils.TensorDataset(X_val, y_val) # create your dataset\n",
    "val_loader = utils.DataLoader(my_dataset, batch_size=10, shuffle=True, num_workers=4) # create your dataloader\n",
    "\n",
    "my_dataset = utils.TensorDataset(X_test, y_test) # create your dataset\n",
    "test_loader = utils.DataLoader(my_dataset, batch_size=10, shuffle=True, num_workers=4) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input 640x480\n",
    "#h=480, w=640\n",
    "#downscaled by 4\n",
    "\n",
    "#output 10 classes\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc1 = nn.Linear(16 * 13 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #print(list(x.size()))\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        #print(list(x.size()))\n",
    "        \n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #print(list(x.size()))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        #print(list(x.size()))\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=1872, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)\n",
    "#if torch.cuda.is_available():\n",
    "#    net.cuda()\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/300] TRAIN acc/loss: 0.300/8.870\n",
      "[Epoch 1/300] VAL   acc/loss: 0.079/9.055\n",
      "[Epoch 2/300] TRAIN acc/loss: 0.100/9.027\n",
      "[Epoch 2/300] VAL   acc/loss: 0.100/9.054\n",
      "[Epoch 3/300] TRAIN acc/loss: 0.100/8.877\n",
      "[Epoch 3/300] VAL   acc/loss: 0.164/8.992\n",
      "[Epoch 4/300] TRAIN acc/loss: 0.300/8.915\n",
      "[Epoch 4/300] VAL   acc/loss: 0.143/8.961\n",
      "[Epoch 5/300] TRAIN acc/loss: 0.300/8.733\n",
      "[Epoch 5/300] VAL   acc/loss: 0.136/8.883\n",
      "[Epoch 6/300] TRAIN acc/loss: 0.200/8.719\n",
      "[Epoch 6/300] VAL   acc/loss: 0.164/8.844\n",
      "[Epoch 7/300] TRAIN acc/loss: 0.300/8.759\n",
      "[Epoch 7/300] VAL   acc/loss: 0.236/8.741\n",
      "[Epoch 8/300] TRAIN acc/loss: 0.000/9.148\n",
      "[Epoch 8/300] VAL   acc/loss: 0.229/8.620\n",
      "[Epoch 9/300] TRAIN acc/loss: 0.100/8.507\n",
      "[Epoch 9/300] VAL   acc/loss: 0.214/8.564\n",
      "[Epoch 10/300] TRAIN acc/loss: 0.100/8.381\n",
      "[Epoch 10/300] VAL   acc/loss: 0.186/8.522\n",
      "[Epoch 11/300] TRAIN acc/loss: 0.000/9.392\n",
      "[Epoch 11/300] VAL   acc/loss: 0.179/8.709\n",
      "[Epoch 12/300] TRAIN acc/loss: 0.400/7.823\n",
      "[Epoch 12/300] VAL   acc/loss: 0.257/8.403\n",
      "[Epoch 13/300] TRAIN acc/loss: 0.700/7.754\n",
      "[Epoch 13/300] VAL   acc/loss: 0.243/8.234\n",
      "[Epoch 14/300] TRAIN acc/loss: 0.500/8.335\n",
      "[Epoch 14/300] VAL   acc/loss: 0.264/8.242\n",
      "[Epoch 15/300] TRAIN acc/loss: 0.300/8.247\n",
      "[Epoch 15/300] VAL   acc/loss: 0.271/8.057\n",
      "[Epoch 16/300] TRAIN acc/loss: 0.500/7.640\n",
      "[Epoch 16/300] VAL   acc/loss: 0.279/7.983\n",
      "[Epoch 17/300] TRAIN acc/loss: 0.500/7.360\n",
      "[Epoch 17/300] VAL   acc/loss: 0.364/7.782\n",
      "[Epoch 18/300] TRAIN acc/loss: 0.300/7.843\n",
      "[Epoch 18/300] VAL   acc/loss: 0.343/7.761\n",
      "[Epoch 19/300] TRAIN acc/loss: 0.500/6.171\n",
      "[Epoch 19/300] VAL   acc/loss: 0.343/7.907\n",
      "[Epoch 20/300] TRAIN acc/loss: 0.600/7.278\n",
      "[Epoch 20/300] VAL   acc/loss: 0.386/7.581\n",
      "[Epoch 21/300] TRAIN acc/loss: 0.600/6.746\n",
      "[Epoch 21/300] VAL   acc/loss: 0.407/7.455\n",
      "[Epoch 22/300] TRAIN acc/loss: 0.800/5.290\n",
      "[Epoch 22/300] VAL   acc/loss: 0.400/7.339\n",
      "[Epoch 23/300] TRAIN acc/loss: 0.600/6.316\n",
      "[Epoch 23/300] VAL   acc/loss: 0.421/7.304\n",
      "[Epoch 24/300] TRAIN acc/loss: 0.600/6.328\n",
      "[Epoch 24/300] VAL   acc/loss: 0.464/7.158\n",
      "[Epoch 25/300] TRAIN acc/loss: 0.500/6.878\n",
      "[Epoch 25/300] VAL   acc/loss: 0.450/7.112\n",
      "[Epoch 26/300] TRAIN acc/loss: 0.300/7.151\n",
      "[Epoch 26/300] VAL   acc/loss: 0.471/6.963\n",
      "[Epoch 27/300] TRAIN acc/loss: 0.500/6.937\n",
      "[Epoch 27/300] VAL   acc/loss: 0.521/6.953\n",
      "[Epoch 28/300] TRAIN acc/loss: 0.600/6.592\n",
      "[Epoch 28/300] VAL   acc/loss: 0.529/6.763\n",
      "[Epoch 29/300] TRAIN acc/loss: 0.500/5.936\n",
      "[Epoch 29/300] VAL   acc/loss: 0.529/6.609\n",
      "[Epoch 30/300] TRAIN acc/loss: 0.700/5.475\n",
      "[Epoch 30/300] VAL   acc/loss: 0.536/6.488\n",
      "[Epoch 31/300] TRAIN acc/loss: 0.800/5.200\n",
      "[Epoch 31/300] VAL   acc/loss: 0.607/6.339\n",
      "[Epoch 32/300] TRAIN acc/loss: 0.400/6.281\n",
      "[Epoch 32/300] VAL   acc/loss: 0.550/6.383\n",
      "[Epoch 33/300] TRAIN acc/loss: 0.800/5.888\n",
      "[Epoch 33/300] VAL   acc/loss: 0.521/6.239\n",
      "[Epoch 34/300] TRAIN acc/loss: 0.900/5.232\n",
      "[Epoch 34/300] VAL   acc/loss: 0.643/5.982\n",
      "[Epoch 35/300] TRAIN acc/loss: 0.700/5.365\n",
      "[Epoch 35/300] VAL   acc/loss: 0.586/6.034\n",
      "[Epoch 36/300] TRAIN acc/loss: 0.800/4.923\n",
      "[Epoch 36/300] VAL   acc/loss: 0.621/6.145\n",
      "[Epoch 37/300] TRAIN acc/loss: 0.500/6.594\n",
      "[Epoch 37/300] VAL   acc/loss: 0.686/5.725\n",
      "[Epoch 38/300] TRAIN acc/loss: 0.800/5.253\n",
      "[Epoch 38/300] VAL   acc/loss: 0.629/5.715\n",
      "[Epoch 39/300] TRAIN acc/loss: 0.700/6.160\n",
      "[Epoch 39/300] VAL   acc/loss: 0.607/5.780\n",
      "[Epoch 40/300] TRAIN acc/loss: 0.600/6.182\n",
      "[Epoch 40/300] VAL   acc/loss: 0.643/5.589\n",
      "[Epoch 41/300] TRAIN acc/loss: 0.800/3.998\n",
      "[Epoch 41/300] VAL   acc/loss: 0.636/5.593\n",
      "[Epoch 42/300] TRAIN acc/loss: 1.000/5.247\n",
      "[Epoch 42/300] VAL   acc/loss: 0.657/5.456\n",
      "[Epoch 43/300] TRAIN acc/loss: 0.800/5.082\n",
      "[Epoch 43/300] VAL   acc/loss: 0.650/5.516\n",
      "[Epoch 44/300] TRAIN acc/loss: 0.800/4.558\n",
      "[Epoch 44/300] VAL   acc/loss: 0.679/5.315\n",
      "[Epoch 45/300] TRAIN acc/loss: 0.800/3.896\n",
      "[Epoch 45/300] VAL   acc/loss: 0.700/5.275\n",
      "[Epoch 46/300] TRAIN acc/loss: 0.900/3.738\n",
      "[Epoch 46/300] VAL   acc/loss: 0.700/5.103\n",
      "[Epoch 47/300] TRAIN acc/loss: 0.900/3.086\n",
      "[Epoch 47/300] VAL   acc/loss: 0.721/4.861\n",
      "[Epoch 48/300] TRAIN acc/loss: 0.800/4.054\n",
      "[Epoch 48/300] VAL   acc/loss: 0.729/4.962\n",
      "[Epoch 49/300] TRAIN acc/loss: 1.000/2.993\n",
      "[Epoch 49/300] VAL   acc/loss: 0.757/4.892\n",
      "[Epoch 50/300] TRAIN acc/loss: 0.700/3.969\n",
      "[Epoch 50/300] VAL   acc/loss: 0.750/4.766\n",
      "[Epoch 51/300] TRAIN acc/loss: 0.800/3.275\n",
      "[Epoch 51/300] VAL   acc/loss: 0.779/4.651\n",
      "[Epoch 52/300] TRAIN acc/loss: 0.900/2.729\n",
      "[Epoch 52/300] VAL   acc/loss: 0.743/4.727\n",
      "[Epoch 53/300] TRAIN acc/loss: 1.000/2.300\n",
      "[Epoch 53/300] VAL   acc/loss: 0.757/4.766\n",
      "[Epoch 54/300] TRAIN acc/loss: 0.900/3.031\n",
      "[Epoch 54/300] VAL   acc/loss: 0.793/4.447\n",
      "[Epoch 55/300] TRAIN acc/loss: 0.800/3.547\n",
      "[Epoch 55/300] VAL   acc/loss: 0.779/4.325\n",
      "[Epoch 56/300] TRAIN acc/loss: 0.900/3.678\n",
      "[Epoch 56/300] VAL   acc/loss: 0.779/4.382\n",
      "[Epoch 57/300] TRAIN acc/loss: 0.700/4.052\n",
      "[Epoch 57/300] VAL   acc/loss: 0.807/4.251\n",
      "[Epoch 58/300] TRAIN acc/loss: 0.900/2.400\n",
      "[Epoch 58/300] VAL   acc/loss: 0.807/4.235\n",
      "[Epoch 59/300] TRAIN acc/loss: 0.900/2.326\n",
      "[Epoch 59/300] VAL   acc/loss: 0.800/4.183\n",
      "[Epoch 60/300] TRAIN acc/loss: 1.000/2.761\n",
      "[Epoch 60/300] VAL   acc/loss: 0.800/4.103\n",
      "[Epoch 61/300] TRAIN acc/loss: 0.700/3.753\n",
      "[Epoch 61/300] VAL   acc/loss: 0.821/4.021\n",
      "[Epoch 62/300] TRAIN acc/loss: 1.000/2.547\n",
      "[Epoch 62/300] VAL   acc/loss: 0.807/3.968\n",
      "[Epoch 63/300] TRAIN acc/loss: 1.000/2.572\n",
      "[Epoch 63/300] VAL   acc/loss: 0.829/3.793\n",
      "[Epoch 64/300] TRAIN acc/loss: 0.900/3.003\n",
      "[Epoch 64/300] VAL   acc/loss: 0.850/3.819\n",
      "[Epoch 65/300] TRAIN acc/loss: 0.900/2.525\n",
      "[Epoch 65/300] VAL   acc/loss: 0.829/3.854\n",
      "[Epoch 66/300] TRAIN acc/loss: 1.000/2.722\n",
      "[Epoch 66/300] VAL   acc/loss: 0.829/3.759\n",
      "[Epoch 67/300] TRAIN acc/loss: 0.900/1.934\n",
      "[Epoch 67/300] VAL   acc/loss: 0.843/3.689\n",
      "[Epoch 68/300] TRAIN acc/loss: 1.000/1.937\n",
      "[Epoch 68/300] VAL   acc/loss: 0.864/3.607\n",
      "[Epoch 69/300] TRAIN acc/loss: 0.900/2.685\n",
      "[Epoch 69/300] VAL   acc/loss: 0.850/3.527\n",
      "[Epoch 70/300] TRAIN acc/loss: 0.900/2.876\n",
      "[Epoch 70/300] VAL   acc/loss: 0.843/3.566\n",
      "[Epoch 71/300] TRAIN acc/loss: 1.000/1.511\n",
      "[Epoch 71/300] VAL   acc/loss: 0.864/3.409\n",
      "[Epoch 72/300] TRAIN acc/loss: 1.000/1.676\n",
      "[Epoch 72/300] VAL   acc/loss: 0.864/3.422\n",
      "[Epoch 73/300] TRAIN acc/loss: 1.000/1.248\n",
      "[Epoch 73/300] VAL   acc/loss: 0.864/3.336\n",
      "[Epoch 74/300] TRAIN acc/loss: 1.000/1.524\n",
      "[Epoch 74/300] VAL   acc/loss: 0.857/3.461\n",
      "[Epoch 75/300] TRAIN acc/loss: 1.000/1.525\n",
      "[Epoch 75/300] VAL   acc/loss: 0.864/3.224\n",
      "[Epoch 76/300] TRAIN acc/loss: 1.000/2.783\n",
      "[Epoch 76/300] VAL   acc/loss: 0.850/3.287\n",
      "[Epoch 77/300] TRAIN acc/loss: 0.900/2.038\n",
      "[Epoch 77/300] VAL   acc/loss: 0.871/3.227\n",
      "[Epoch 78/300] TRAIN acc/loss: 1.000/1.178\n",
      "[Epoch 78/300] VAL   acc/loss: 0.879/3.076\n",
      "[Epoch 79/300] TRAIN acc/loss: 1.000/1.221\n",
      "[Epoch 79/300] VAL   acc/loss: 0.879/3.200\n",
      "[Epoch 80/300] TRAIN acc/loss: 0.900/2.328\n",
      "[Epoch 80/300] VAL   acc/loss: 0.864/3.092\n",
      "[Epoch 81/300] TRAIN acc/loss: 1.000/1.270\n",
      "[Epoch 81/300] VAL   acc/loss: 0.879/2.952\n",
      "[Epoch 82/300] TRAIN acc/loss: 1.000/1.445\n",
      "[Epoch 82/300] VAL   acc/loss: 0.893/3.143\n",
      "[Epoch 83/300] TRAIN acc/loss: 1.000/1.678\n",
      "[Epoch 83/300] VAL   acc/loss: 0.879/3.024\n",
      "[Epoch 84/300] TRAIN acc/loss: 0.900/1.378\n",
      "[Epoch 84/300] VAL   acc/loss: 0.900/2.928\n",
      "[Epoch 85/300] TRAIN acc/loss: 1.000/1.408\n",
      "[Epoch 85/300] VAL   acc/loss: 0.879/3.129\n",
      "[Epoch 86/300] TRAIN acc/loss: 1.000/1.275\n",
      "[Epoch 86/300] VAL   acc/loss: 0.871/2.885\n",
      "[Epoch 87/300] TRAIN acc/loss: 1.000/1.069\n",
      "[Epoch 87/300] VAL   acc/loss: 0.900/2.900\n",
      "[Epoch 88/300] TRAIN acc/loss: 1.000/1.171\n",
      "[Epoch 88/300] VAL   acc/loss: 0.871/2.802\n",
      "[Epoch 89/300] TRAIN acc/loss: 1.000/1.038\n",
      "[Epoch 89/300] VAL   acc/loss: 0.886/2.783\n",
      "[Epoch 90/300] TRAIN acc/loss: 1.000/1.510\n",
      "[Epoch 90/300] VAL   acc/loss: 0.893/2.723\n",
      "[Epoch 91/300] TRAIN acc/loss: 1.000/2.004\n",
      "[Epoch 91/300] VAL   acc/loss: 0.886/2.810\n",
      "[Epoch 92/300] TRAIN acc/loss: 1.000/1.831\n",
      "[Epoch 92/300] VAL   acc/loss: 0.886/2.717\n",
      "[Epoch 93/300] TRAIN acc/loss: 1.000/1.224\n",
      "[Epoch 93/300] VAL   acc/loss: 0.886/2.645\n",
      "[Epoch 94/300] TRAIN acc/loss: 1.000/1.392\n",
      "[Epoch 94/300] VAL   acc/loss: 0.900/2.757\n",
      "[Epoch 95/300] TRAIN acc/loss: 1.000/0.693\n",
      "[Epoch 95/300] VAL   acc/loss: 0.893/2.588\n",
      "[Epoch 96/300] TRAIN acc/loss: 1.000/1.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/300] VAL   acc/loss: 0.886/2.791\n",
      "[Epoch 97/300] TRAIN acc/loss: 1.000/1.152\n",
      "[Epoch 97/300] VAL   acc/loss: 0.893/2.655\n",
      "[Epoch 98/300] TRAIN acc/loss: 1.000/1.239\n",
      "[Epoch 98/300] VAL   acc/loss: 0.900/2.669\n",
      "[Epoch 99/300] TRAIN acc/loss: 1.000/0.735\n",
      "[Epoch 99/300] VAL   acc/loss: 0.914/2.529\n",
      "[Epoch 100/300] TRAIN acc/loss: 1.000/1.287\n",
      "[Epoch 100/300] VAL   acc/loss: 0.886/2.722\n",
      "[Epoch 101/300] TRAIN acc/loss: 1.000/0.466\n",
      "[Epoch 101/300] VAL   acc/loss: 0.900/2.448\n",
      "[Epoch 102/300] TRAIN acc/loss: 1.000/0.539\n",
      "[Epoch 102/300] VAL   acc/loss: 0.900/2.441\n",
      "[Epoch 103/300] TRAIN acc/loss: 1.000/0.604\n",
      "[Epoch 103/300] VAL   acc/loss: 0.907/2.464\n",
      "[Epoch 104/300] TRAIN acc/loss: 1.000/0.598\n",
      "[Epoch 104/300] VAL   acc/loss: 0.893/2.381\n",
      "[Epoch 105/300] TRAIN acc/loss: 1.000/0.714\n",
      "[Epoch 105/300] VAL   acc/loss: 0.886/2.531\n",
      "[Epoch 106/300] TRAIN acc/loss: 1.000/0.998\n",
      "[Epoch 106/300] VAL   acc/loss: 0.907/2.400\n",
      "[Epoch 107/300] TRAIN acc/loss: 1.000/0.692\n",
      "[Epoch 107/300] VAL   acc/loss: 0.900/2.513\n",
      "[Epoch 108/300] TRAIN acc/loss: 1.000/0.794\n",
      "[Epoch 108/300] VAL   acc/loss: 0.907/2.359\n",
      "[Epoch 109/300] TRAIN acc/loss: 1.000/0.348\n",
      "[Epoch 109/300] VAL   acc/loss: 0.886/2.411\n",
      "[Epoch 110/300] TRAIN acc/loss: 1.000/0.938\n",
      "[Epoch 110/300] VAL   acc/loss: 0.900/2.295\n",
      "[Epoch 111/300] TRAIN acc/loss: 1.000/0.688\n",
      "[Epoch 111/300] VAL   acc/loss: 0.900/2.239\n",
      "[Epoch 112/300] TRAIN acc/loss: 1.000/0.650\n",
      "[Epoch 112/300] VAL   acc/loss: 0.900/2.327\n",
      "[Epoch 113/300] TRAIN acc/loss: 1.000/0.553\n",
      "[Epoch 113/300] VAL   acc/loss: 0.900/2.288\n",
      "[Epoch 114/300] TRAIN acc/loss: 1.000/0.556\n",
      "[Epoch 114/300] VAL   acc/loss: 0.921/2.280\n",
      "[Epoch 115/300] TRAIN acc/loss: 1.000/0.451\n",
      "[Epoch 115/300] VAL   acc/loss: 0.879/2.250\n",
      "[Epoch 116/300] TRAIN acc/loss: 1.000/0.236\n",
      "[Epoch 116/300] VAL   acc/loss: 0.907/2.132\n",
      "[Epoch 117/300] TRAIN acc/loss: 1.000/0.212\n",
      "[Epoch 117/300] VAL   acc/loss: 0.900/2.263\n",
      "[Epoch 118/300] TRAIN acc/loss: 1.000/0.500\n",
      "[Epoch 118/300] VAL   acc/loss: 0.907/2.265\n",
      "[Epoch 119/300] TRAIN acc/loss: 1.000/0.365\n",
      "[Epoch 119/300] VAL   acc/loss: 0.907/2.293\n",
      "[Epoch 120/300] TRAIN acc/loss: 1.000/0.307\n",
      "[Epoch 120/300] VAL   acc/loss: 0.907/2.242\n",
      "[Epoch 121/300] TRAIN acc/loss: 1.000/0.561\n",
      "[Epoch 121/300] VAL   acc/loss: 0.929/2.194\n",
      "[Epoch 122/300] TRAIN acc/loss: 1.000/0.426\n",
      "[Epoch 122/300] VAL   acc/loss: 0.893/2.166\n",
      "[Epoch 123/300] TRAIN acc/loss: 1.000/0.800\n",
      "[Epoch 123/300] VAL   acc/loss: 0.900/2.191\n",
      "[Epoch 124/300] TRAIN acc/loss: 1.000/0.561\n",
      "[Epoch 124/300] VAL   acc/loss: 0.900/2.232\n",
      "[Epoch 125/300] TRAIN acc/loss: 1.000/0.292\n",
      "[Epoch 125/300] VAL   acc/loss: 0.914/2.137\n",
      "[Epoch 126/300] TRAIN acc/loss: 1.000/0.422\n",
      "[Epoch 126/300] VAL   acc/loss: 0.886/2.246\n",
      "[Epoch 127/300] TRAIN acc/loss: 1.000/0.207\n",
      "[Epoch 127/300] VAL   acc/loss: 0.900/2.162\n",
      "[Epoch 128/300] TRAIN acc/loss: 1.000/0.272\n",
      "[Epoch 128/300] VAL   acc/loss: 0.900/2.081\n",
      "[Epoch 129/300] TRAIN acc/loss: 1.000/0.387\n",
      "[Epoch 129/300] VAL   acc/loss: 0.900/2.095\n",
      "[Epoch 130/300] TRAIN acc/loss: 1.000/0.179\n",
      "[Epoch 130/300] VAL   acc/loss: 0.914/2.037\n",
      "[Epoch 131/300] TRAIN acc/loss: 1.000/0.242\n",
      "[Epoch 131/300] VAL   acc/loss: 0.914/2.067\n",
      "[Epoch 132/300] TRAIN acc/loss: 1.000/0.530\n",
      "[Epoch 132/300] VAL   acc/loss: 0.914/2.066\n",
      "[Epoch 133/300] TRAIN acc/loss: 1.000/0.169\n",
      "[Epoch 133/300] VAL   acc/loss: 0.900/2.020\n",
      "[Epoch 134/300] TRAIN acc/loss: 1.000/0.301\n",
      "[Epoch 134/300] VAL   acc/loss: 0.893/2.078\n",
      "[Epoch 135/300] TRAIN acc/loss: 1.000/0.162\n",
      "[Epoch 135/300] VAL   acc/loss: 0.914/1.989\n",
      "[Epoch 136/300] TRAIN acc/loss: 1.000/0.243\n",
      "[Epoch 136/300] VAL   acc/loss: 0.914/2.106\n",
      "[Epoch 137/300] TRAIN acc/loss: 1.000/0.220\n",
      "[Epoch 137/300] VAL   acc/loss: 0.914/2.002\n",
      "[Epoch 138/300] TRAIN acc/loss: 1.000/0.244\n",
      "[Epoch 138/300] VAL   acc/loss: 0.907/2.116\n",
      "[Epoch 139/300] TRAIN acc/loss: 1.000/0.202\n",
      "[Epoch 139/300] VAL   acc/loss: 0.893/1.941\n",
      "[Epoch 140/300] TRAIN acc/loss: 1.000/0.137\n",
      "[Epoch 140/300] VAL   acc/loss: 0.936/1.940\n",
      "[Epoch 141/300] TRAIN acc/loss: 1.000/0.251\n",
      "[Epoch 141/300] VAL   acc/loss: 0.929/1.914\n",
      "[Epoch 142/300] TRAIN acc/loss: 1.000/0.183\n",
      "[Epoch 142/300] VAL   acc/loss: 0.907/1.986\n",
      "[Epoch 143/300] TRAIN acc/loss: 1.000/0.213\n",
      "[Epoch 143/300] VAL   acc/loss: 0.914/1.901\n",
      "[Epoch 144/300] TRAIN acc/loss: 1.000/0.326\n",
      "[Epoch 144/300] VAL   acc/loss: 0.907/1.902\n",
      "[Epoch 145/300] TRAIN acc/loss: 1.000/0.144\n",
      "[Epoch 145/300] VAL   acc/loss: 0.907/1.876\n",
      "[Epoch 146/300] TRAIN acc/loss: 1.000/0.125\n",
      "[Epoch 146/300] VAL   acc/loss: 0.929/1.857\n",
      "[Epoch 147/300] TRAIN acc/loss: 1.000/0.267\n",
      "[Epoch 147/300] VAL   acc/loss: 0.914/1.909\n",
      "[Epoch 148/300] TRAIN acc/loss: 1.000/0.161\n",
      "[Epoch 148/300] VAL   acc/loss: 0.921/1.915\n",
      "[Epoch 149/300] TRAIN acc/loss: 1.000/0.249\n",
      "[Epoch 149/300] VAL   acc/loss: 0.914/1.906\n",
      "[Epoch 150/300] TRAIN acc/loss: 1.000/0.157\n",
      "[Epoch 150/300] VAL   acc/loss: 0.929/1.906\n",
      "[Epoch 151/300] TRAIN acc/loss: 1.000/0.216\n",
      "[Epoch 151/300] VAL   acc/loss: 0.929/1.881\n",
      "[Epoch 152/300] TRAIN acc/loss: 1.000/0.123\n",
      "[Epoch 152/300] VAL   acc/loss: 0.921/1.863\n",
      "[Epoch 153/300] TRAIN acc/loss: 1.000/0.243\n",
      "[Epoch 153/300] VAL   acc/loss: 0.921/1.835\n",
      "[Epoch 154/300] TRAIN acc/loss: 1.000/0.156\n",
      "[Epoch 154/300] VAL   acc/loss: 0.936/1.797\n",
      "[Epoch 155/300] TRAIN acc/loss: 1.000/0.123\n",
      "[Epoch 155/300] VAL   acc/loss: 0.907/1.867\n",
      "[Epoch 156/300] TRAIN acc/loss: 1.000/0.109\n",
      "[Epoch 156/300] VAL   acc/loss: 0.921/1.848\n",
      "[Epoch 157/300] TRAIN acc/loss: 1.000/0.144\n",
      "[Epoch 157/300] VAL   acc/loss: 0.936/1.930\n",
      "[Epoch 158/300] TRAIN acc/loss: 1.000/0.169\n",
      "[Epoch 158/300] VAL   acc/loss: 0.907/1.882\n",
      "[Epoch 159/300] TRAIN acc/loss: 1.000/0.182\n",
      "[Epoch 159/300] VAL   acc/loss: 0.907/1.904\n",
      "[Epoch 160/300] TRAIN acc/loss: 1.000/0.144\n",
      "[Epoch 160/300] VAL   acc/loss: 0.907/1.860\n",
      "[Epoch 161/300] TRAIN acc/loss: 1.000/0.108\n",
      "[Epoch 161/300] VAL   acc/loss: 0.936/1.827\n",
      "[Epoch 162/300] TRAIN acc/loss: 1.000/0.102\n",
      "[Epoch 162/300] VAL   acc/loss: 0.921/1.786\n",
      "[Epoch 163/300] TRAIN acc/loss: 1.000/0.111\n",
      "[Epoch 163/300] VAL   acc/loss: 0.914/1.814\n",
      "[Epoch 164/300] TRAIN acc/loss: 1.000/0.148\n",
      "[Epoch 164/300] VAL   acc/loss: 0.907/1.822\n",
      "[Epoch 165/300] TRAIN acc/loss: 1.000/0.103\n",
      "[Epoch 165/300] VAL   acc/loss: 0.921/1.746\n",
      "[Epoch 166/300] TRAIN acc/loss: 1.000/0.155\n",
      "[Epoch 166/300] VAL   acc/loss: 0.936/1.756\n",
      "[Epoch 167/300] TRAIN acc/loss: 1.000/0.105\n",
      "[Epoch 167/300] VAL   acc/loss: 0.929/1.795\n",
      "[Epoch 168/300] TRAIN acc/loss: 1.000/0.104\n",
      "[Epoch 168/300] VAL   acc/loss: 0.943/1.723\n",
      "[Epoch 169/300] TRAIN acc/loss: 1.000/0.162\n",
      "[Epoch 169/300] VAL   acc/loss: 0.929/1.764\n",
      "[Epoch 170/300] TRAIN acc/loss: 1.000/0.065\n",
      "[Epoch 170/300] VAL   acc/loss: 0.914/1.794\n",
      "[Epoch 171/300] TRAIN acc/loss: 1.000/0.111\n",
      "[Epoch 171/300] VAL   acc/loss: 0.936/1.782\n",
      "[Epoch 172/300] TRAIN acc/loss: 1.000/0.082\n",
      "[Epoch 172/300] VAL   acc/loss: 0.900/1.859\n",
      "[Epoch 173/300] TRAIN acc/loss: 1.000/0.084\n",
      "[Epoch 173/300] VAL   acc/loss: 0.929/1.727\n",
      "[Epoch 174/300] TRAIN acc/loss: 1.000/0.061\n",
      "[Epoch 174/300] VAL   acc/loss: 0.929/1.766\n",
      "[Epoch 175/300] TRAIN acc/loss: 1.000/0.116\n",
      "[Epoch 175/300] VAL   acc/loss: 0.900/1.841\n",
      "[Epoch 176/300] TRAIN acc/loss: 1.000/0.058\n",
      "[Epoch 176/300] VAL   acc/loss: 0.936/1.702\n",
      "[Epoch 177/300] TRAIN acc/loss: 1.000/0.057\n",
      "[Epoch 177/300] VAL   acc/loss: 0.914/1.796\n",
      "[Epoch 178/300] TRAIN acc/loss: 1.000/0.059\n",
      "[Epoch 178/300] VAL   acc/loss: 0.929/1.675\n",
      "[Epoch 179/300] TRAIN acc/loss: 1.000/0.088\n",
      "[Epoch 179/300] VAL   acc/loss: 0.929/1.737\n",
      "[Epoch 180/300] TRAIN acc/loss: 1.000/0.065\n",
      "[Epoch 180/300] VAL   acc/loss: 0.907/1.721\n",
      "[Epoch 181/300] TRAIN acc/loss: 1.000/0.062\n",
      "[Epoch 181/300] VAL   acc/loss: 0.936/1.664\n",
      "[Epoch 182/300] TRAIN acc/loss: 1.000/0.127\n",
      "[Epoch 182/300] VAL   acc/loss: 0.914/1.760\n",
      "[Epoch 183/300] TRAIN acc/loss: 1.000/0.084\n",
      "[Epoch 183/300] VAL   acc/loss: 0.929/1.712\n",
      "[Epoch 184/300] TRAIN acc/loss: 1.000/0.088\n",
      "[Epoch 184/300] VAL   acc/loss: 0.921/1.692\n",
      "[Epoch 185/300] TRAIN acc/loss: 1.000/0.056\n",
      "[Epoch 185/300] VAL   acc/loss: 0.936/1.685\n",
      "[Epoch 186/300] TRAIN acc/loss: 1.000/0.060\n",
      "[Epoch 186/300] VAL   acc/loss: 0.921/1.713\n",
      "[Epoch 187/300] TRAIN acc/loss: 1.000/0.084\n",
      "[Epoch 187/300] VAL   acc/loss: 0.921/1.709\n",
      "[Epoch 188/300] TRAIN acc/loss: 1.000/0.057\n",
      "[Epoch 188/300] VAL   acc/loss: 0.929/1.666\n",
      "[Epoch 189/300] TRAIN acc/loss: 1.000/0.168\n",
      "[Epoch 189/300] VAL   acc/loss: 0.914/1.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 190/300] TRAIN acc/loss: 1.000/0.084\n",
      "[Epoch 190/300] VAL   acc/loss: 0.907/1.804\n"
     ]
    }
   ],
   "source": [
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "num_epochs = 300\n",
    "iter_per_epoch = len(train_loader)\n",
    "#224 lines -> 112 val output for log_nth=10000\n",
    "#1120000 iter\n",
    "#log_nth = 16\n",
    "log_nth = 1000\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    for i, (inputs, targets) in enumerate(train_loader, 1):\n",
    "        inputs, targets = Variable(inputs.float()), Variable(targets.float())\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss_history.append(loss.data.cpu().numpy())\n",
    "        if log_nth and i % log_nth == 0:\n",
    "            last_log_nth_losses = train_loss_history[-log_nth:]\n",
    "            train_loss = np.mean(last_log_nth_losses)\n",
    "            print('[Iteration %d/%d] TRAIN loss: %.3f' % \\\n",
    "                        (i + epoch * iter_per_epoch,\n",
    "                         iter_per_epoch * num_epochs,\n",
    "                         train_loss))\n",
    "            \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    _, target_indices = torch.max(targets, 1)\n",
    "    #print(preds)\n",
    "    #print(targets)\n",
    "    train_acc = np.mean((preds == target_indices).data.cpu().numpy())\n",
    "    train_acc_history.append(train_acc)\n",
    "    if log_nth:\n",
    "        print('[Epoch %d/%d] TRAIN acc/loss: %.3f/%.3f' % (epoch + 1,\n",
    "                                                            num_epochs,\n",
    "                                                            train_acc,\n",
    "                                                            loss))\n",
    "        '''_, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Only allow images/pixels with label >= 0 e.g. for segmentation\n",
    "        targets_mask = labels >= 0\n",
    "        train_acc = np.mean((preds == targets)[targets_mask].data.cpu().numpy())\n",
    "        train_acc_history.append(train_acc)\n",
    "        if log_nth:\n",
    "            print('[Epoch %d/%d] TRAIN acc/loss: %.3f/%.3f' % (epoch + 1,\n",
    "                                                                   num_epochs,\n",
    "                                                                   train_acc,\n",
    "                                                                   train_loss))'''\n",
    "        \n",
    "    # VALIDATION\n",
    "    val_losses = []\n",
    "    val_scores = []\n",
    "    model.eval()\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        _, target_indices = torch.max(targets, 1)\n",
    "\n",
    "        scores = np.mean((preds == target_indices).data.cpu().numpy())\n",
    "        val_scores.append(scores)\n",
    "\n",
    "    model.train()\n",
    "    val_acc, val_loss = np.mean(val_scores), np.mean(val_losses)\n",
    "    val_acc_history.append(val_acc)\n",
    "    val_loss_history.append(val_loss)\n",
    "    if log_nth:\n",
    "        print('[Epoch %d/%d] VAL   acc/loss: %.3f/%.3f' % (epoch + 1,\n",
    "                                                            num_epochs,\n",
    "                                                            val_acc,\n",
    "                                                            val_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "path = \"saved_models/lenet_rgb_\" + str(num_epochs) + \"_\" + currentDT + \".model\"\n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% -> 10 epochs\n",
    "#87% -> 50 epochs\n",
    "\n",
    "scores = []\n",
    "for inputs, target in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    _, target_indices = torch.max(targets, 1)\n",
    "    scores.extend((preds == target_indices).data.cpu().numpy())\n",
    "    \n",
    "print('Test set accuracy: %f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_history, '-')\n",
    "#plt.plot(val_loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc_history, '-o')\n",
    "plt.plot(val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for inputs, target in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    _, target_indices = torch.max(targets, 1)\n",
    "    scores.extend((preds == target_indices).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for inputs, target in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    _, target_indices = torch.max(targets, 1)\n",
    "    \n",
    "    numpy_inputs = inputs.data.cpu().numpy()\n",
    "    numpy_outputs = outputs.data.cpu().numpy()\n",
    "    numpy_targets = targets.data.cpu().numpy()\n",
    "    \n",
    "    img = numpy_inputs[0]\n",
    "    img = img[0, :, :]\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Predicted: \"+str(preds[0].item()) + \" Target: \"+str(target_indices[0].item()))\n",
    "    plt.show()\n",
    "    #currentDT = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    #path = \"images/img_\" + currentDT + \".png\"\n",
    "    #plt.imsave(path, img.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
